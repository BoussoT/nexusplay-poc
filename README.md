# NexusPlay POC â€“ Plateforme de Mini-jeux Multijoueurs

Prototype dâ€™architecture cloud-native (Kubernetes + microservices Node.js) avec CI/CD, autoscaling, cache Redis, monitoring, test de charge, gestion sÃ©curisÃ©e des secrets et pipeline complet.

---

## ğŸš€ FonctionnalitÃ©s ImplÃ©mentÃ©es

* **Microservices Node.js** :

  * `user-service` : gestion utilisateurs, endpoint santÃ©.
  * `game-service` : gestion des parties, compteur via Redis.
* **Orchestration Kubernetes (Minikube)** :

  * DÃ©ploiements, services (`NodePort` et `Ingress`).
  * Autoscaling automatique avec HPA.
  * Gestion sÃ©curisÃ©e des secrets (Kubernetes Secrets).
  * Cache partagÃ© Redis dÃ©ployÃ© dans le cluster.
* **CI/CD GitHub Actions** :

  * Build, tests, dÃ©ploiement automatisÃ© via runner auto-hÃ©bergÃ©.
  * Test de charge automatisÃ© via ApacheBench.
  * Notifications dâ€™incidents prÃªtes Ã  lâ€™emploi (webhook Slack).
* **Monitoring** :

  * Visualisation des mÃ©triques des pods/services.
* **DNS Haute disponibilitÃ©** : CoreDNS (K8s).

---

## ğŸ—ï¸ Architecture

![image](https://github.com/user-attachments/assets/067d022d-0c76-4c09-a259-9cd80c68187d)


---

## ğŸ“‚ Organisation du dÃ©pÃ´t

```
nexusplay-poc/
â”‚
â”œâ”€â”€ microservices/
â”‚   â”œâ”€â”€ user-service/
â”‚   â””â”€â”€ game-service/
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ user-deployment.yaml
â”‚   â”œâ”€â”€ game-deployment.yaml
â”‚   â”œâ”€â”€ redis-deployment.yaml
â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”œâ”€â”€ hpa-user.yaml
â”‚   â”œâ”€â”€ hpa-game.yaml
â”‚   â””â”€â”€ secrets.yaml
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci-cd.yml
â”‚
â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ (values.yaml, autres manifests si besoin)
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ DÃ©ploiement local rapide

### 1. **PrÃ©requis**

* Docker, Minikube, kubectl, Helm, Node.js

### 2. **DÃ©marrage Minikube**

```bash
minikube start --memory=4096 --cpus=2
minikube addons enable ingress
minikube addons enable metrics-server
```

### 3. **Build images Docker dans Minikube**

```bash
eval $(minikube docker-env)
docker build -t user-service:latest ./microservices/user-service
docker build -t game-service:latest ./microservices/game-service
```

### 4. **DÃ©ploiement des manifests K8s**

```bash
kubectl apply -f k8s/
```

### 5. **VÃ©rifier les services et accÃ©der Ã  lâ€™API**

```bash
kubectl get svc
kubectl get ingress
minikube ip
```

AccÃ¨s typique :

* `http://<minikube ip>:32122/user/status`
* `http://<minikube ip>:32123/game/play`
* ou via Ingressâ€¯: `http://<minikube ip>/user/status`

---

## ğŸ” Pipeline CI/CD (GitHub Actions)

* Build, test, build Docker, dÃ©ploiement K8s et test de charge automatisÃ©s
* Runner auto-hÃ©bergÃ© connectÃ© Ã  Minikube
* **Test de charge** via ApacheBench (`ab`)
* Notifications prÃªtes pour Slack (variable secrÃ¨te Ã  fournir)

---

## ğŸ“¸ **Captures & RÃ©sultats**

### **1. CI/CD â€“ ExÃ©cution des jobs et gestion des Ã©checs/rÃ©ussites**

# Lancement du notre runner self hosted

![image](https://github.com/user-attachments/assets/e075f722-2183-4a0c-8492-49979a0e8ef5)


![image](https://github.com/user-attachments/assets/b5907c0a-a208-4a24-ba06-45bd836694ae)


# Pipeline Successful

![image](https://github.com/user-attachments/assets/b4660ce2-7984-4de9-975e-b54eb50c9212)



---

### **2. Test de Charge â€“ ApacheBench**

![image](https://github.com/user-attachments/assets/a6ff78ce-67af-4687-8dc0-7a23c5690258)


---

### **3. Monitoring (Grafana)**



![image](https://github.com/user-attachments/assets/3b031ffc-aaaa-49d6-b7f4-3eba3bf3a60c)


---

### **4. notification SLACK**


![image](https://github.com/user-attachments/assets/3da416bf-89d4-46a6-a033-5c1f6c09d0a6)


---



## âš ï¸ Limitations & Points Ã  amÃ©liorer

* **Ressources** : environnement local limitÃ©, certains outils de monitoring lourds difficilement utilisables en continu.
* **Notification incident** : webhook Slack non activÃ© (pas de credentials de test fournis).
* **Tests unitaires** : non approfondis, placeholder dans la CI.
* **Pas de vÃ©ritable cloud/HA multi-nÅ“uds**, mais la logique K8s est rÃ©plicable sur cloud provider.
* **Monitoring allÃ©gÃ© selon la charge** (Prometheus/Grafana).
* **CoreDNS** utilisÃ© comme DNS K8s, mais pas de scÃ©nario â€œfailover DNSâ€ explicite (hors scope Minikube single-node).

---


